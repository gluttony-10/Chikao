import os
import gradio as gr
import base64
import requests
import time
import json
import random
from io import BytesIO
import argparse
from openai import OpenAI
from pathlib import Path
from datetime import datetime

parser = argparse.ArgumentParser() 
parser.add_argument("--server_name", type=str, default="127.0.0.1", help="IPåœ°å€ï¼Œå±€åŸŸç½‘è®¿é—®æ”¹ä¸º0.0.0.0")
parser.add_argument("--server_port", type=int, default=7891, help="ä½¿ç”¨ç«¯å£")
parser.add_argument("--share", action="store_true", help="æ˜¯å¦å¯ç”¨gradioå…±äº«")
parser.add_argument("--mcp_server", action="store_true", help="æ˜¯å¦å¯ç”¨mcpæœåŠ¡")
args = parser.parse_args()

os.makedirs("outputs", exist_ok=True)


BASE_URL = "https://api.modelverse.cn/v1"

MODEL_CHOICES = [
    "openai/sora-2/image-to-video-pro",
    "openai/sora-2/image-to-video",
    "openai/sora-2/text-to-video-pro",
    "openai/sora-2/text-to-video",
    "Wan-AI/Wan2.2-I2V",
    "Wan-AI/Wan2.2-T2V",
    "Wan-AI/Wan2.5-I2V",
    "Wan-AI/Wan2.5-T2V"
]

TTS_MODEL_CHOICES = [
    "IndexTeam/IndexTTS-2"
]

TTS_VOICE_CHOICES = [
    "jack_cheng",
    "sales_voice",
    "crystla_liu",
    "stephen_chow",
    "xiaoyueyue",
    "mkas",
    "entertain",
    "novel",
    "movie"
]


def image_to_base64(image):
    """
    å°†PILå›¾åƒè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²
    """
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"


def submit_task(api_key, first_frame_image, last_frame_image, prompt, size, duration, model, negative_prompt=None, seed=None, enable_prompt_expansion=False, audio_url=None):
    """
    æäº¤å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡
    """
    headers = {
        "Authorization": api_key,
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": model
    }
    
    # æ ¹æ®æ¨¡å‹ç±»å‹æ„å»ºä¸åŒçš„è¾“å…¥å‚æ•°
    if "image-to-video" in model:
        if first_frame_image is None:
            raise Exception("Image-to-video models require an input image")
        first_frame_url = image_to_base64(first_frame_image)
        payload["input"] = {
            "first_frame_url": first_frame_url
        }
        if prompt:
            payload["input"]["prompt"] = prompt
            
        # æ·»åŠ å‚æ•°éƒ¨åˆ†
        if "pro" in model:
            # å¯¹äºproç‰ˆæœ¬ï¼Œä½¿ç”¨resolutionå‚æ•°
            resolution_map = {
                "720x1280": "720P",
                "1280x720": "720P",
                "1024x1792": "1080P",
                "1792x1024": "1080P"
            }
            resolution = resolution_map.get(size, "720P")
            payload["parameters"] = {
                "resolution": resolution,
                "duration": duration
            }
        else:
            payload["parameters"] = {
                "size": size,
                "duration": duration
            }
    elif "text-to-video" in model:
        if not prompt:
            raise Exception("Text-to-video models require a prompt")
        payload["input"] = {
            "prompt": prompt
        }
        
        # æ·»åŠ å‚æ•°éƒ¨åˆ†
        payload["parameters"] = {
            "size": size,
            "duration": duration
        }
    elif model == "Wan-AI/Wan2.2-I2V":
        # å¤„ç† Wan-AI/Wan2.2-I2V æ¨¡å‹
        if first_frame_image is None:
            raise Exception("Wan-AI/Wan2.2-I2V model requires an input image")
        first_frame_url = image_to_base64(first_frame_image)
        if not prompt:
            raise Exception("Wan-AI/Wan2.2-I2V model requires a prompt")
            
        payload["input"] = {
            "first_frame_url": first_frame_url,
            "prompt": prompt
        }
        # æ·»åŠ å°¾å¸§å›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
        if last_frame_image is not None:
            last_frame_url = image_to_base64(last_frame_image)
            payload["input"]["last_frame_url"] = last_frame_url
        if negative_prompt:
            payload["input"]["negative_prompt"] = negative_prompt
        
        # è®¾ç½®åˆ†è¾¨ç‡å‚æ•° (ä»…æ”¯æŒ 720P å’Œ 480P)
        resolution_map = {
            "720x1280": "720P",
            "1280x720": "720P",
            "832x480": "480P",
            "480x832": "480P"
        }
        resolution = resolution_map.get(size, "720P")
        payload["parameters"] = {
            "resolution": resolution
        }
        if seed is not None:
            # å¦‚æœç§å­å°äº0ï¼Œåœ¨å…è®¸èŒƒå›´å†…ç”Ÿæˆéšæœºç§å­
            if seed < 0:
                if model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
                    # 2.2ç‰ˆæœ¬ç§å­èŒƒå›´: [0, 2147483647]
                    seed = random.randint(0, 2147483647)
                else:
                    # 2.5ç‰ˆæœ¬æ”¯æŒ-1è¡¨ç¤ºéšæœºï¼Œä½†ä¹Ÿå¯ä»¥ç”Ÿæˆå…¶ä»–éšæœºæ•°
                    seed = random.randint(0, 2147483647)
            payload["parameters"]["seed"] = seed
    elif model == "Wan-AI/Wan2.2-T2V":
        # å¤„ç† Wan-AI/Wan2.2-T2V æ¨¡å‹
        if not prompt:
            raise Exception("Wan-AI/Wan2.2-T2V model requires a prompt")
            
        payload["input"] = {
            "prompt": prompt
        }
        if negative_prompt:
            payload["input"]["negative_prompt"] = negative_prompt
        
        # è®¾ç½®å‚æ•°
        payload["parameters"] = {
            "size": size,
            "resolution": "720P" if "1280" in size or "720" in size else "480P"
        }
        if seed is not None:
            # å¦‚æœç§å­å°äº0ï¼Œåœ¨å…è®¸èŒƒå›´å†…ç”Ÿæˆéšæœºç§å­
            if seed < 0:
                if model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
                    # 2.2ç‰ˆæœ¬ç§å­èŒƒå›´: [0, 2147483647]
                    seed = random.randint(0, 2147483647)
                else:
                    # 2.5ç‰ˆæœ¬æ”¯æŒ-1è¡¨ç¤ºéšæœºï¼Œä½†ä¹Ÿå¯ä»¥ç”Ÿæˆå…¶ä»–éšæœºæ•°
                    seed = random.randint(0, 2147483647)
            payload["parameters"]["seed"] = seed
    elif model == "Wan-AI/Wan2.5-I2V":
        # å¤„ç† Wan-AI/Wan2.5-I2V æ¨¡å‹
        if first_frame_image is None:
            raise Exception("Wan-AI/Wan2.5-I2V model requires an input image")
        first_frame_url = image_to_base64(first_frame_image)
        if not prompt:
            raise Exception("Wan-AI/Wan2.5-I2V model requires a prompt")
            
        payload["input"] = {
            "first_frame_url": first_frame_url,
            "prompt": prompt
        }
        # æ·»åŠ å°¾å¸§å›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
        if last_frame_image is not None:
            last_frame_url = image_to_base64(last_frame_image)
            payload["input"]["last_frame_url"] = last_frame_url
        if negative_prompt:
            payload["input"]["negative_prompt"] = negative_prompt
        # æ·»åŠ éŸ³é¢‘ URLï¼ˆå¦‚æœæä¾›ï¼‰
        if audio_url:
            payload["input"]["audio_url"] = audio_url
        
        # è®¾ç½®åˆ†è¾¨ç‡å‚æ•° (æ”¯æŒ 480p, 720p, 1080p)
        resolution_map = {
            "720x1280": "720p",
            "1280x720": "720p",
            "832x480": "480p",
            "480x832": "480p",
            "1920x1080": "1080p",
            "1080x1920": "1080p"
        }
        resolution = resolution_map.get(size, "720p")
        payload["parameters"] = {
            "resolution": resolution,
            "duration": duration
        }
        if enable_prompt_expansion:
            payload["parameters"]["prompt_extend"] = enable_prompt_expansion
        if seed is not None:
            # å¦‚æœç§å­å°äº0ï¼Œåœ¨å…è®¸èŒƒå›´å†…ç”Ÿæˆéšæœºç§å­
            if seed < 0:
                if model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
                    # 2.2ç‰ˆæœ¬ç§å­èŒƒå›´: [0, 2147483647]
                    seed = random.randint(0, 2147483647)
                else:
                    # 2.5ç‰ˆæœ¬æ”¯æŒ-1è¡¨ç¤ºéšæœºï¼Œä½†ä¹Ÿå¯ä»¥ç”Ÿæˆå…¶ä»–éšæœºæ•°
                    seed = random.randint(0, 2147483647)
            payload["parameters"]["seed"] = seed
    elif model == "Wan-AI/Wan2.5-T2V":
        # å¤„ç† Wan-AI/Wan2.5-T2V æ¨¡å‹
        if not prompt:
            raise Exception("Wan-AI/Wan2.5-T2V model requires a prompt")
            
        payload["input"] = {
            "prompt": prompt
        }
        if negative_prompt:
            payload["input"]["negative_prompt"] = negative_prompt
        # æ·»åŠ éŸ³é¢‘ URLï¼ˆå¦‚æœæä¾›ï¼‰
        if audio_url:
            payload["input"]["audio_url"] = audio_url
        
        # è®¾ç½®å‚æ•°
        payload["parameters"] = {
            "size": size,
            "duration": duration
        }
        if enable_prompt_expansion:
            payload["parameters"]["prompt_extend"] = enable_prompt_expansion
        if seed is not None:
            # å¦‚æœç§å­å°äº0ï¼Œåœ¨å…è®¸èŒƒå›´å†…ç”Ÿæˆéšæœºç§å­
            if seed < 0:
                if model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
                    # 2.2ç‰ˆæœ¬ç§å­èŒƒå›´: [0, 2147483647]
                    seed = random.randint(0, 2147483647)
                else:
                    # 2.5ç‰ˆæœ¬æ”¯æŒ-1è¡¨ç¤ºéšæœºï¼Œä½†ä¹Ÿå¯ä»¥ç”Ÿæˆå…¶ä»–éšæœºæ•°
                    seed = random.randint(0, 2147483647)
            payload["parameters"]["seed"] = seed
    
    response = requests.post(f"{BASE_URL}/tasks/submit",
                            headers=headers,
                            data=json.dumps(payload),
                            timeout=30)
    
    if response.status_code == 200:
        result = response.json()
        task_id = result["output"]["task_id"]
        return task_id
    else:
        raise Exception(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥: {response.text}")
    

def check_task_status(api_key, task_id):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    """
    headers = {
        "Authorization": api_key
    }
    
    response = requests.get(f"{BASE_URL}/tasks/status?task_id={task_id}", 
                           headers=headers)
    
    if response.status_code == 200:
        return response.json()
    else:
        raise Exception(f"âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {response.text}")


def download_video(url, filename):
    """
    ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
    """
    response = requests.get(url)
    if response.status_code == 200:
        with open(filename, 'wb') as f:
            f.write(response.content)
        return filename
    else:
        raise Exception(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {response.status_code}")


def generate_speech(api_key, model, text, voice):
    """
    ç”Ÿæˆè¯­éŸ³ - ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Modelverse TTS API
    """
    try:
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.modelverse.cn/v1/",
        )
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        
        # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶è·¯å¾„
        speech_file_path = Path(__file__).parent / f"outputs/{timestamp}_{voice}.wav"
        
        # è°ƒç”¨ TTS API
        with client.audio.speech.with_streaming_response.create(
            model=model,
            voice=voice,
            input=text,
        ) as response:
            response.stream_to_file(speech_file_path)
        
        return str(speech_file_path)
        
    except Exception as e:
        raise Exception(f"âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {str(e)}")


def generate_audio(api_key, model, text, voice):
    """
    ä¸»å‡½æ•°ï¼šç”Ÿæˆè¯­éŸ³
    """
    try:
        # æ£€æŸ¥è¾“å…¥å‚æ•°
        if not api_key:
            return "âŒ è¯·è¾“å…¥API KEY", None
        if not text:
            return "âŒ è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬", None
        if len(text) > 600:
            return "âŒ æ–‡æœ¬é•¿åº¦ä¸èƒ½è¶…è¿‡600å­—ç¬¦", None
        
        # ä½¿ç”¨ OpenAI SDK ç”Ÿæˆè¯­éŸ³ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„
        audio_file_path = generate_speech(api_key, model, text, voice)
        
        return f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæ¯•", audio_file_path
        
    except Exception as e:
        return f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}", None


def generate_video(api_key, first_frame_image, last_frame_image, prompt, size, duration, model, negative_prompt=None, seed=None, enable_prompt_expansion=False, audio_url=None, video_state=None):
    """
    ä¸»å‡½æ•°ï¼šä¸Šä¼ å›¾ç‰‡ï¼Œæäº¤ä»»åŠ¡ï¼Œè½®è¯¢çŠ¶æ€å¹¶ä¸‹è½½ç»“æœ
    """
    try:
        # æäº¤ä»»åŠ¡
        task_id = submit_task(api_key, first_frame_image, last_frame_image, prompt, size, duration, model, negative_prompt, seed, enable_prompt_expansion, audio_url)
        # ç¡®ä¿ video_state æ˜¯åˆ—è¡¨
        current_videos = video_state if video_state is not None else []
        yield f"ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}", current_videos, current_videos
        
        # è½®è¯¢ä»»åŠ¡çŠ¶æ€
        while True:
            time.sleep(5)  # æ¯5ç§’æŸ¥è¯¢ä¸€æ¬¡
            
            status_result = check_task_status(api_key, task_id)
            task_status = status_result["output"]["task_status"]
            
            if task_status == "Success":
                video_urls = status_result["output"]["urls"]
                # å°†æ–°è§†é¢‘æ·»åŠ åˆ°ç°æœ‰è§†é¢‘åˆ—è¡¨ä¸­
                updated_videos = current_videos + video_urls
                yield f"âœ… è§†é¢‘ç”Ÿæˆå®Œæ¯•", updated_videos, updated_videos
                break
            elif task_status == "Failure":
                error_msg = status_result["output"].get("error_message", "æœªçŸ¥é”™è¯¯")
                yield f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}", current_videos, current_videos
                break
            else:
                yield f"ä»»åŠ¡çŠ¶æ€: {task_status}...", current_videos, current_videos
                
    except Exception as e:
        current_videos = video_state if video_state is not None else []
        yield f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}", current_videos, current_videos


def update_visibility(model):
    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ›´æ–°ç•Œé¢å…ƒç´ çš„å¯è§æ€§
    if model == "Wan-AI/Wan2.2-I2V":
        # åªæœ‰Wan-AI/Wan2.2-I2Væ”¯æŒå°¾å¸§
        return gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)
    elif "image-to-video" in model or model in ["Wan-AI/Wan2.5-I2V"]:
        # å…¶ä»–i2væ¨¡å‹ä¸æ”¯æŒå°¾å¸§
        return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False)
    else:
        return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)


def update_negative_prompt_visibility(model):
    # æ›´æ–°è´Ÿå‘æç¤ºè¯çš„å¯è§æ€§
    # åªæœ‰Wan-AIæ¨¡å‹æ”¯æŒnegative_prompt
    return gr.update(visible=model.startswith("Wan-AI"))
    

def update_resolution_choices(model):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°å¯ç”¨çš„åˆ†è¾¨ç‡é€‰é¡¹"""
    if "pro" in model:
        # proç‰ˆæœ¬æ”¯æŒæ‰€æœ‰åˆ†è¾¨ç‡
        return gr.update(
            choices=["720x1280", "1280x720", "1024x1792", "1792x1024"],
            value="720x1280",
            visible=True
        )
    elif model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
        # Wan-AI 2.2 æ¨¡å‹åªæ”¯æŒç‰¹å®šåˆ†è¾¨ç‡
        return gr.update(
            choices=["720x1280", "1280x720", "832x480", "480x832"],
            value="720x1280",
            visible=True
        )
    elif model in ["Wan-AI/Wan2.5-I2V", "Wan-AI/Wan2.5-T2V"]:
        # Wan-AI 2.5 æ¨¡å‹æ”¯æŒæ–°åˆ†è¾¨ç‡é€‰é¡¹
        return gr.update(
            choices=["720x1280", "1280x720", "832x480", "480x832", "1920x1080", "1080x1920"],
            value="720x1280",
            visible=True
        )
    else:
        # éproç‰ˆæœ¬åªæ”¯æŒ720x1280å’Œ1280x720
        return gr.update(
            choices=["720x1280", "1280x720"],
            value="720x1280",
            visible=True
        )
        

def update_duration_slider(model):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°æ—¶é•¿æ»‘å—"""
    if model in ["Wan-AI/Wan2.5-I2V", "Wan-AI/Wan2.5-T2V"]:
        return gr.update(
            minimum=5,
            maximum=10,
            step=5,
            value=5,
            visible=True
        )
    elif model in ["Wan-AI/Wan2.2-I2V", "Wan-AI/Wan2.2-T2V"]:
        return gr.update(
            minimum=5,
            maximum=5,
            step=5,
            value=5,
            visible=True
        )
    elif model in ["openai/sora-2/image-to-video-pro", "openai/sora-2/text-to-video-pro"]:
        return gr.update(
            minimum=4,
            maximum=12,
            step=4,
            value=4,
            visible=True
        )
    else:
        return gr.update(
            minimum=4,
            maximum=12,
            step=4,
            value=4,
            visible=True
        )


def update_prompt_expansion_visibility(model):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°æç¤ºè¯ä¼˜åŒ–çš„å¯è§æ€§"""
    # Wan-AI 2.5-I2V å’Œ Wan2.5-T2V æ¨¡å‹éƒ½æ”¯æŒæç¤ºè¯ä¼˜åŒ–
    # Wan2.2æ¨¡å‹æ²¡æœ‰è¿™ä¸ªå‚æ•°
    return gr.update(visible=model in ["Wan-AI/Wan2.5-I2V", "Wan-AI/Wan2.5-T2V"])


def update_audio_url_visibility(model):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°éŸ³é¢‘URLçš„å¯è§æ€§"""
    # åªæœ‰Wan-AI 2.5æ¨¡å‹æ”¯æŒéŸ³é¢‘URL
    return gr.update(visible=model in ["Wan-AI/Wan2.5-I2V", "Wan-AI/Wan2.5-T2V"])


def update_seed_visibility(model):
    """æ ¹æ®æ¨¡å‹ç±»å‹æ›´æ–°éšæœºæ•°ç§å­çš„å¯è§æ€§"""
    # åªæœ‰Wan-AIæ¨¡å‹æ”¯æŒseed
    return gr.update(visible=model.startswith("Wan-AI"))


with gr.Blocks(title="ä¼˜äº‘æ™ºç®— APIè°ƒç”¨ åœ¨çº¿ä½“éªŒ", theme=gr.themes.Soft(font=[gr.themes.GoogleFont("IBM Plex Sans")])) as demo:
    gr.Markdown("""
            <div>
                <h2 style="font-size: 30px;text-align: center;">ä¼˜äº‘æ™ºç®— APIè°ƒç”¨ åœ¨çº¿ä½“éªŒ</h2>
            </div>
            <div style="text-align: center;">
                ä½¿ç”¨è¯´æ˜ï¼šä½“éªŒå‰è¯·å…ˆå‰å¾€ <b><a href="https://www.compshare.cn/?ytag=GPU_YY-SZY_Gradio">ä¼˜äº‘æ™ºç®—</a></b> å¹³å°æ³¨å†Œå®åï¼Œæ–°ç”¨æˆ·ç«‹å¾—10å…ƒèµ é‡‘ã€‚
            </div>
            <div style="text-align: center; font-weight: bold; color: red;">
                âš ï¸ æœ¬å·¥å…·ä»…æä¾›APIè°ƒç”¨ç•Œé¢ï¼Œç”¨æˆ·éœ€å¯¹ç”Ÿæˆå†…å®¹æ‰¿æ‹…å…¨éƒ¨è´£ä»»ã€‚è¯·ç¡®ä¿éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„ï¼Œä¸ç”Ÿæˆä»»ä½•è¿æ³•è¿è§„å†…å®¹ã€‚
            </div>
            """)
    
    # åˆ›å»ºçŠ¶æ€å˜é‡æ¥å­˜å‚¨å·²ç”Ÿæˆçš„è§†é¢‘
    video_state = gr.State([])
    api_key_input = gr.Textbox(
                label="API KEYï¼ˆå¿…å¡«ï¼‰",
                info="(è¯·å…ˆå» [ä¼˜äº‘æ™ºç®—](https://console.compshare.cn/light-gpu/api-keys?ytag=GPU_YY-SZY_Gradio) åˆ›å»ºAPI KEY)",
                placeholder="è¯·è¾“å…¥æ‚¨çš„API KEY...",
                type="password"
            )
    with gr.Tabs():
        with gr.TabItem("è§†é¢‘ç”Ÿæˆ"):
            with gr.Row():
                with gr.Column():
                    model_choice = gr.Dropdown(
                        choices=MODEL_CHOICES,
                        value="openai/sora-2/image-to-video",
                        label="é€‰æ‹©æ¨¡å‹"
                    )
                    with gr.Row():
                        first_frame = gr.Image(type="pil", label="é¦–å¸§å›¾ç‰‡", visible=True, height=300)
                        last_frame = gr.Image(type="pil", label="å°¾å¸§å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰", visible=False, height=300)
                    prompt = gr.Textbox(label="æç¤ºè¯", placeholder="è¯·è¾“å…¥æç¤ºè¯æŒ‡å¯¼è§†é¢‘ç”Ÿæˆ...")
                    negative_prompt = gr.Textbox(label="è´Ÿé¢æç¤ºè¯ï¼ˆå¯é€‰ï¼‰", placeholder="è¯·è¾“å…¥ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹...", visible=False)
                    audio_url = gr.Textbox(label="éŸ³é¢‘ URLï¼ˆå¯é€‰ï¼‰", placeholder="è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶ URLï¼ˆå¯é€‰ï¼‰...", visible=False)
                    size = gr.Dropdown(
                        choices=["720x1280", "1280x720", "1024x1792", "1792x1024"],
                        value="720x1280",
                        label="è§†é¢‘å°ºå¯¸"
                    )
                    duration = gr.Slider(
                        minimum=4,
                        maximum=12,
                        step=1,
                        value=4,
                        label="è§†é¢‘æ—¶é•¿ (ç§’)"
                    )
                    seed = gr.Number(label="ç§å­", value=-1, info="-1è¡¨ç¤ºéšæœº", visible=False)
                    enable_prompt_expansion = gr.Checkbox(label="å¯ç”¨æç¤ºè¯ä¼˜åŒ–", visible=False)
                    submit_btn = gr.Button("ğŸ¬ å¼€å§‹ç”Ÿæˆ", variant="primary")
                with gr.Column():
                    status_output = gr.Textbox(label="ä»»åŠ¡çŠ¶æ€", interactive=False)
                    gr.Markdown("è§†é¢‘ç”Ÿæˆåï¼Œè¯·ç‚¹å‡»ä¸‹è½½æŒ‰é’®æ‰‹åŠ¨ä¿å­˜ã€‚åˆ·æ–°ç•Œé¢ä¼šå¯¼è‡´è§†é¢‘ç”Ÿæˆç»“æœä¸¢å¤±ã€‚")
                    video_output = gr.Gallery(label="è§†é¢‘ç”Ÿæˆ", columns=2, height=800, object_fit="contain")
                    gr.Markdown("æ›´å¤šä½¿ç”¨æ–¹æ³•è¯¦è§[APIè°ƒç”¨æ–‡æ¡£](https://www.compshare.cn/docs/modelverse/models/audio_api/ttts/?ytag=GPU_YY-SZY_Gradio)")
        
        with gr.TabItem("éŸ³é¢‘ç”Ÿæˆ"):
            with gr.Row():
                with gr.Column():
                    tts_model_choice = gr.Dropdown(
                        choices=TTS_MODEL_CHOICES,
                        value="IndexTeam/IndexTTS-2",
                        label="é€‰æ‹©è¯­éŸ³æ¨¡å‹"
                    )
                    voice_choice = gr.Dropdown(
                        choices=TTS_VOICE_CHOICES,
                        value="jack_cheng",
                        label="é€‰æ‹©éŸ³è‰²"
                    )
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡æœ¬å†…å®¹ï¼ˆæœ€å¤§æ”¯æŒ600å­—ç¬¦ï¼‰...",
                    )
                    submit_audio_btn = gr.Button("ğŸµ ç”Ÿæˆè¯­éŸ³", variant="primary")
                with gr.Column():
                    audio_status_output = gr.Textbox(label="ç”ŸæˆçŠ¶æ€", interactive=False)
                    audio_output = gr.Audio(label="ç”Ÿæˆçš„è¯­éŸ³", type="filepath", interactive=False, autoplay=True, show_download_button=True)
                    gr.Markdown("æ›´å¤šä½¿ç”¨æ–¹æ³•è¯¦è§[APIè°ƒç”¨æ–‡æ¡£](https://www.compshare.cn/docs/modelverse/models/audio_api/ttts/?ytag=GPU_YY-SZY_Gradio)")

    model_choice.change(
        fn=lambda model: [
            update_visibility(model)[0],
            update_visibility(model)[1],
            update_visibility(model)[2],
            update_negative_prompt_visibility(model),
            update_resolution_choices(model),
            update_duration_slider(model),
            update_seed_visibility(model),
            update_prompt_expansion_visibility(model),
            update_audio_url_visibility(model)
        ],
        inputs=model_choice,
        outputs=[first_frame, prompt, last_frame, negative_prompt, size, duration, seed, enable_prompt_expansion, audio_url]
    )

    # è§†é¢‘ç”Ÿæˆäº‹ä»¶å¤„ç†
    gr.on(
        triggers=[submit_btn.click, prompt.submit],
        fn=generate_video,
        inputs=[api_key_input, first_frame, last_frame, prompt, size, duration, model_choice, negative_prompt, seed, enable_prompt_expansion, audio_url, video_state],
        outputs=[status_output, video_output, video_state]
    )
    
    # éŸ³é¢‘ç”Ÿæˆäº‹ä»¶å¤„ç†
    gr.on(
        triggers=[submit_audio_btn.click, text_input.submit],
        fn=generate_audio,
        inputs=[api_key_input, tts_model_choice, text_input, voice_choice],
        outputs=[audio_status_output, audio_output]
    )


if __name__ == "__main__":
    demo.launch(
        server_name=args.server_name,
        server_port=args.server_port,
        share=args.share,
        mcp_server=args.mcp_server,
        inbrowser=True,
    )